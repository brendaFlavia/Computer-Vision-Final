{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DELL\\Documents\\Cropping\\try.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39margparse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimutils\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\t\n",
    "\tcv2.normalize(hist, hist)\n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_feature(image):\n",
    "    # Applying the function\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "    kp, des = orb.detectAndCompute(gray_scale, None)\n",
    "  \n",
    "# Drawing the keypoints\n",
    "    kp_image = cv2.drawKeypoints(gray_scale, kp, None, color=(0, 255, 0), flags=0)\n",
    "    #cv2.normalize(kp_image, kp_image)\n",
    "    return kp_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT_Feature(image):\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#initialize SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "#detect keypoints\n",
    "    keypoints, _= sift.detectAndCompute(image, None)\n",
    "#draw keypoints\n",
    "    sift_image = cv2.drawKeypoints(gray_scale, keypoints, None)\n",
    "    #cv2.normalize(sift_image, sift_image)\n",
    "    return sift_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def Average(lst):\n",
    "    return mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get the filenames of the leaves under the directory “Leaves”\n",
    " image_path_list = os.listdir(\"bananas_cropped\")\n",
    " # looking at the first image\n",
    " #i = 0\n",
    " #image_path = image_path_list[i]\n",
    " #image = rgb2gray(imread(\"bananas_cropped/\"+image_path))\n",
    " #imshow((image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] describing images...\")\n",
    "#imagePaths = list(os.listdir(image_path_list))\n",
    "# initialize the raw pixel intensities matrix, the features matrix,\n",
    "# and labels list\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []\n",
    "org_fe=[]\n",
    "sift=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_path_list)):\n",
    "\t# load the image and extract the class label (assuming that our\n",
    "\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "\timage_path = image_path_list[i]\n",
    "\t#image = rgb2gray(imread(\"bananas_cropped/\"+image_path))\n",
    "\timage = cv2.imread(\"bananas_cropped/\"+image_path)\n",
    "\tlabel = image_path[0:14]\n",
    "\t# extract raw pixel intensity \"features\", followed by a color\n",
    "\t# histogram to characterize the color distribution of the pixels\n",
    "\t# in the image\n",
    "\t\n",
    "\torg=org_feature(image)\n",
    "\tpixels = image_to_feature_vector(image)\n",
    "\thist = extract_color_histogram(image)\n",
    "\tsift_fe=SIFT_Feature(image)\n",
    "\t# update the raw images, features, and labels matricies,\n",
    "\t# respectively\n",
    "\trawImages.append(pixels)\n",
    "\tfeatures.append(hist)\n",
    "\torg_fe.append(Average(org))\n",
    "\tsift.append(Average(sift_fe))\n",
    "\tlabels.append(label)\n",
    "\t# show an update every 1,000 images\n",
    "\tif i > 0 and i % 1000 == 0:\n",
    "\t\tprint(\"[INFO] processed {}/{}\".format(i, len(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_images = pd.DataFrame(rawImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist=pd.DataFrame(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sift=pd.DataFrame(sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org=pd.DataFrame(org_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img=pd.DataFrame(labels)\n",
    "df_sift_org=pd.merge(df_sift,df_org,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_feature1=pd.merge(df_img,df_raw_images, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_feature3=pd.merge(df_all_feature2,df_hist, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_feature=pd.merge(df_all_feature1,df_hist, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 0_x  0_y   1    2   3    4    5   6   7   8  ...  3063  3064  \\\n",
       "0     Bananas_1.jpg  -16 -21  -24  -9  -20  -27 -16 -24 -24  ...    40    73   \n",
       "1    Bananas_10.jpg  -24 -30  -31  79   53   38  74  45  30  ...    11    22   \n",
       "2    Bananas_100.jp   70  72   61  49   45   41  47  43  31  ...    35   100   \n",
       "3    Bananas_101.jp   47  46   36 -39  -43  -48  37  40  28  ...    46    98   \n",
       "4    Bananas_102.jp   -8 -11  -16  87   64   46  77  60  52  ...     2    18   \n",
       "..              ...  ...  ..  ...  ..  ...  ...  ..  ..  ..  ...   ...   ...   \n",
       "417  Cassava_95.jpg   37  55   60   1   15   12  31  53  50  ...     8    37   \n",
       "418  Cassava_96.jpg    3  22   27  80  100  102   1  14  10  ...    17    44   \n",
       "419  Cassava_97.jpg    0  16   22  74   93   97   0  20  15  ...    17    44   \n",
       "420  Cassava_98.jpg   63  96  109  10   17   13  27  48  49  ...     6    30   \n",
       "421  Cassava_99.jpg   45  84   98   9   22   15  48  62  65  ...     1    21   \n",
       "\n",
       "     3065  3066  3067  3068  3069  3070  3071         0  \n",
       "0      62    18    42    34    93   116   116  0.008224  \n",
       "1      20     5    28    24    43    64    58  0.002263  \n",
       "2      76    16    25    24    11    16    17  0.002131  \n",
       "3      80     7    18    17     5    13     7  0.002528  \n",
       "4      11    13    24    16    27    48    42  0.002565  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "417    26     8    24    17    10    20    14  0.000000  \n",
       "418    31    46    60    54     9    18    16  0.000000  \n",
       "419    31    16    29    22     6    20    14  0.000000  \n",
       "420    21    23    39    32     6    19    16  0.000000  \n",
       "421    13    12    26    20     2    11     5  0.000000  \n",
       "\n",
       "[422 rows x 3074 columns]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_feature.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_class (row):\n",
    "   if 'Banana' in row['0_x'] :\n",
    "      return 1\n",
    "   if 'Cassava' in row['0_x'] :\n",
    "      return 0\n",
    "   return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0_x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DELL\\Documents\\Cropping\\try.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_all_feature[\u001b[39m'\u001b[39m\u001b[39mclass_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_all_feature\u001b[39m.\u001b[39;49mapply (\u001b[39mlambda\u001b[39;49;00m row: image_class(row), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:8740\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8729\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8731\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   8732\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   8733\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8738\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   8739\u001b[0m )\n\u001b[1;32m-> 8740\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:688\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    686\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 688\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:812\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 812\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    814\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:828\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    826\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    827\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    829\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    830\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    831\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    832\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\DELL\\Documents\\Cropping\\try.ipynb Cell 22\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_all_feature[\u001b[39m'\u001b[39m\u001b[39mclass_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_all_feature\u001b[39m.\u001b[39mapply (\u001b[39mlambda\u001b[39;00m row: image_class(row), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\DELL\\Documents\\Cropping\\try.ipynb Cell 22\u001b[0m in \u001b[0;36mimage_class\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_class\u001b[39m (row):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m    \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mBanana\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m row[\u001b[39m'\u001b[39;49m\u001b[39m0_x\u001b[39;49m\u001b[39m'\u001b[39;49m] :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/Documents/Cropping/try.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m    \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCassava\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m row[\u001b[39m'\u001b[39m\u001b[39m0_x\u001b[39m\u001b[39m'\u001b[39m] :\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py:942\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    941\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 942\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    944\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    945\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    946\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py:1051\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1050\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1052\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3363\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mand\u001b[39;00m isna(key) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhasnans:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0_x'"
     ]
    }
   ],
   "source": [
    "df_all_feature['class_label'] = df_all_feature.apply (lambda row: image_class(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty=df_all_feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 0_x  0_y   1   2   3   4   5   6   7    8  ...  3064  3065  \\\n",
       "0     Bananas_1.jpg  -16 -21 -24  -9 -20 -27 -16 -24  -24  ...    73    62   \n",
       "1    Bananas_10.jpg  -24 -30 -31  79  53  38  74  45   30  ...    22    20   \n",
       "2    Bananas_100.jp   70  72  61  49  45  41  47  43   31  ...   100    76   \n",
       "3    Bananas_101.jp   47  46  36 -39 -43 -48  37  40   28  ...    98    80   \n",
       "4    Bananas_102.jp   -8 -11 -16  87  64  46  77  60   52  ...    18    11   \n",
       "..              ...  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...   ...   ...   \n",
       "507  Bananas_176.jp  -18 -24 -29  86  60  50 -23 -28  -26  ...    29    20   \n",
       "508  Bananas_177.jp  -50 -55 -60  81  57  42  -9 -21  -21  ...    27    19   \n",
       "509  Bananas_178.jp  -10 -16 -21  92  59  41 -85 -98 -101  ...    20    18   \n",
       "510  Bananas_179.jp  -75 -79 -84  86  63  40  87  70   61  ...    24    15   \n",
       "511  Bananas_18.jpg  -26 -29 -33  70  51  34  67  46   31  ...    77    71   \n",
       "\n",
       "     3066  3067  3068  3069  3070  3071         0  class_label  \n",
       "0      18    42    34    93   116   116  0.008224            1  \n",
       "1       5    28    24    43    64    58  0.002263            1  \n",
       "2      16    25    24    11    16    17  0.002131            1  \n",
       "3       7    18    17     5    13     7  0.002528            1  \n",
       "4      13    24    16    27    48    42  0.002565            1  \n",
       "..    ...   ...   ...   ...   ...   ...       ...          ...  \n",
       "507     3    12     9     8    32    32  0.000000            1  \n",
       "508    10    20    14     8    34    34  0.000000            1  \n",
       "509    11    17    15     6    23    24  0.000000            1  \n",
       "510  -103   -88   -94    63    74    72  0.000000            1  \n",
       "511    25    58    49    78   103   107  0.000000            1  \n",
       "\n",
       "[512 rows x 3075 columns]>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_feature.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df_all_feature['class_label'].value_counts().index, df_all_feature['class_label'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "#Standardizing the Input Features\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70530371 -0.70078028 -0.74490106 ...  1.91494954 -0.11048077\n",
      "   0.83725544]\n",
      " [-0.88759321 -0.87276556 -0.88140404 ...  0.44287236 -0.25148561\n",
      "   0.83725544]\n",
      " [ 1.25430841  1.0764009   0.91263519 ... -0.59773393 -0.25460914\n",
      "   0.83725544]\n",
      " ...\n",
      " [-0.56858658 -0.60523291 -0.68639978 ... -0.42006944 -0.30503176\n",
      "   0.83725544]\n",
      " [-2.04968877 -1.80912984 -1.91492665 ...  0.79820133 -0.30503176\n",
      "   0.83725544]\n",
      " [-0.93316558 -0.85365608 -0.9204049  ...  1.68652377 -0.30503176\n",
      "   0.83725544]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = df_all_feature['class_label']\n",
    "X = df_all_feature.drop('class_label', axis = 1)\n",
    "X = df_all_feature.drop('0_x', axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)\n",
    "# Separating the dependent and independent variable\n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             X, y, test_size = 0.2, random_state = 125)\n",
    "# Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "neigh.fit(X_train, y_train)\n",
    "#KNeighborsClassifier(...)\n",
    "print(neigh.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.09%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {np.mean(neigh.score(X_test,y_test))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 2.53MB\n",
      "[INFO] features matrix: 1.69MB\n"
     ]
    }
   ],
   "source": [
    "# show some information on the memory consumed by the raw images\n",
    "# matrix and features matrix\n",
    "rawImages = np.array(rawImages)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.25, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=15)\n",
    "model.fit(trainRI, trainRL)\n",
    "acc = model.score(testRI, testRL)\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] histogram accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifer on the histogram\n",
    "# representations\n",
    "print(\"[INFO] evaluating histogram accuracy...\")\n",
    "model = KNeighborsClassifier(n_neighbors=25)\n",
    "model.fit(trainFeat, trainLabels)\n",
    "acc = model.score(testFeat, testLabels)\n",
    "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
